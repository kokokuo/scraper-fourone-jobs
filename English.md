# scraper-fourone-jobs

## Translation Assistance Need you ğŸ™ğŸ™ğŸ™
You're welcome to come to this repository. If you like the repository, hope you could give me a Star. If you are interested, the current English translation is in progress. Really welcome the **fork** project and assist to translate and send PR :)

[![License: GPL v2](https://img.shields.io/badge/License-GPL%20v2-blue.svg)](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html) [![Python 3.7.1](https://img.shields.io/badge/Python-3.7.1-blue.svg)](https://www.python.org/downloads/release/python-371/)

<p align="center">
  <img src="../master/Images/Program-Result.png?raw=true" width="640px">
</p>

scraper-fourone-jobs is a anti-scraping cracker for extracting apply information of one of Taiwan famous jobs recruiting website, this program **only for learning and researching how to crack anti-scraping, please DO NOT use for commercial**.

The reason for creating the project is that saw a question that someone asked how to do scraping for this website in "Python Taiwan Community" of Facebook group, and in the processing of answering, I think that need to write program by myself, and then will know what the detail, even though there are some tips how to crack.

The project was completed in 2019.06.28, and the website will change to other anti-scraping method by the time, so the program will crashed in the future. If you discover the problem, free feel to send a PR or Issue thanks!

**<p align="center">The data would lke to scrape and show the HTML source.</p>**
<p align="center">
  <img src="../master/Images/Anti-scraping-fourone-jobs-apply-contents.png?raw=true" width="640px">
</p>

## Prerequisite
- Development enviromentï¼š `vscode`
- Language versionï¼š `Python 3.7`
- Packageï¼š `pipenv`, `fonttools`, `lxml`, `requests`

## How to Crack

The program which would like to scrape and extract data is from the recruitment page and the data "email", "telephone" and "mobile" could not scrape from correct way like XPATH, it's will show unmeaningful data and encoding, here is the HTML page source as below.

**<p align="center">HTML Page Source Content</p>**
<p align="center">
  <img src="../master/Images/Anti-scraping-css-font-class-style.png?raw=true" width="640px">
</p>

### 1. Anti-scraping analyzing

In anti-scraping, ths situation for showing data correct but HTML page source is unmeaningful and weired content, the reason almost caused by Javascript dynamic handling or CSS font encoding. For the javascript, it could change the content after DOM loaded or some event triggred. In CSS, it could change the text style by CSS attribute.
 
As time goes by analyzing and reading the source by DevTools, found the possible source is `txticon` ths class selector from CSS, and discover the user-defined font value `'runes'` from `font-family` attribute: 

**<p align="center">The CSS style declaration of txticon</p>**
<p align="center">
  <img src="../master/Images/Anti-scraping-css-font-family-and-font-file.png?raw=true" width="640px">
</p>

Usually when you found the user-defined font value from `font-family`, it's means the anti-scraping method from CSS font encoding.

<br/>

### 2. Search font file used for encoding of CSS anti-scraping

Because the font of `font-family ` is user-defined, the source font file must exsit, so the website could show the correct content. After searching the files location further, there were a path called `webService/NET40/Runes/fonts/Books` and the user-defined font CSS `xxxxx.css` was put in here with the font file `xxxxx.woff?v0001` and named randomly.

First, open the file which the extension is `.css` and you will see the `font-face` attribute and the user-defined value `runes`. The `font-face` is CSS3 new property and it could assist the developer providing more types of fonts to users, but the more interesting usuage is that `font-face` was used for anti-scraping protection.


**<p align="center">User-defined font-family font named runes location</p>**
<p align="center">
  <img src="../master/Images/Anti-scraping-font-face-custom-font-url.png?raw=true" width="640px">
</p>

And the attribute `url` could discover which font format was used, but only find [(Web Open Font Format)](https://zh.wikipedia.org/wiki/Web%E9%96%8B%E6%94%BE%E5%AD%97%E5%9E%8B%E6%A0%BC%E5%BC%8F), and mapped the file of directory `webService/NET40/Runes/fonts/Books`, the font extension is `.woff?v0001`.

But the file name looks like **automatically and randomly generated**,  the encoding of font content also could be different, so I have to download the file more times and check the HTML scraping source font of encoding again for checking the encoding is different or not.

Then copy the font file URL path and download it for tring to analyze the content of font. After we know the rule,  we could build a scraper process to automatically download file and parse garbled words, then map word to the encoding for translation to correct contents.


<br/>

### 3. Download font file for analyzing

After downloading the font files, then start to analyze the content of font, because the font record different character and the encoding for translating to show character.

Although the words are garbled when we parsed them from HTML, but if we put the garbled words into font file, then the font file will figure out these character of garbled words and map to translate correct character.

This is reason why we need to download the font file first. But the problem is the scraping process not a browser, so we need to make more effort to analyze and parse it by ourself.

### 3.1 Analyze font content by FontCreator or FontDrop

After we know the reason, then we start to talk about analysing, if the people use the Windows operation, then suggest to install the software called **[FontCreator](https://www.linksoft.com.tw/product/fontcreator)**. The software could assist us to understand th contents of font file and visualizing the contents, like we could see the 16 bit Unicode each font.

**<p align="center">FontCreator Viewer Sample</p>**
<p align="center">
  <img src="../master/Images/Font-Creator-Sample.png?raw=true" width="640px">
</p>

The above image sample are not from "jobs recruiting website", it's another [anti-scraping tutorial sample](https://www.itread01.com/content/1547172845.html). We'll see the font `å·¦` map to the unicode encoding `uniED8C`. (The prefix `uni` we could omit it)

But we could use the **FontCreator** software on a MacOS, so I recommend to use the website service called **[FontDrop!](https://fontdrop.info/)**. **[FontDrop!](https://fontdrop.info/)** has the powerful functions on viewer, we just need to import font file, now upload the font file downloaded from "jobs recruiting website":

**<p align="center">FontDrop! Viewer</p>**
<p align="center">
  <img src="../master/Images/FontDrop-Sample-1-View-Fonts.png?raw=true" width="640px">
</p>

We'll see the different fonts on the above image and all of the font map to one unicode encoding, we could click the font to see the detail information:

**<p align="center">FontDrop! Detail Font Viewer</p>**
<p align="center">
  <img src="../master/Images/FontDrop-Sample-2-View-Detail.png?raw=true" width="640px">
</p>

First thing is why there are many unicode encoding? Acutually not only one unicode encoding map to one character in the font file, but each font have a main unicode encoding, like the sample `(` map to `E19B` encoding.

The other two important information is **Index** and **Contours data** :

+ **Index** : Means the order of the font list.
+ **Contours data** : Means the contours of the font and will represent by coordinates to draw.

The above two arguments are the keypoint for assisting check the font if CSS anti-scraping difficulty increase, and we'll talk later.


### 3.2 Use fonttools of python package to read data 

After we know the reason, we could write a program to do it automatically. Install the Python package called `fonttools`. The package could get the content from font file through reading file path or binary content with `TTFont` and then saved to XML format with `saveXML`: 

```python
import io
import requests
from fontTools.ttLib import TTFont

...

url = "The URL path of font file "
resp = requests.get(url)

# If read the font file directly => TTFont("Font file path")
font = TTFont(io.BytesIO(resp.content))
font.saveXML("saved file path")
```


The reason for saving to XML format file is that it's still hard to read the right data from `fonttools` even although we know the content of font by visualizing from **FontCreator** and **FontDrop!** tools before. 

Because we could not know which methods could find the data we want. and that why we need to save to XML file format first and then call the right method by mapping to the content in the XML.

Here, `TTFont` could analyze and parse content from font according to different font format. Each font format has different specification to to recording encoding font, like **[WOFF - Web Open Font Format](https://zh.wikipedia.org/wiki/Web%E9%96%8B%E6%94%BE%E5%AD%97%E5%9E%8B%E6%A0%BC%E5%BC%8F#cite_note-10)**, **[TTF - TrueType](https://zh.wikipedia.org/wiki/TrueType)** and **[EOT - Embedded OpenType](https://zh.wikipedia.org/wiki/%E5%B5%8C%E5%85%A5%E5%BC%8FOpenType)** and record encoding and description of font with different tags and attributes.


Okay, let's open the saved font file of XML format to analyze the contents.


#### (1.) `GlyphOrder` and `GlyphID` tags - Font indexing and unicode mapping

**GlyphOrder** and **GlyphID** tagsï¼šThese two tags could record the all different fonts orderly.
Each tags of **GlyphID** describe the font through **Unicode** and **Index** attribute. The information is the same information as **Index** int the **FontDrop!**, so we could know every font meaning through the visualization in the **FontDrop!**.

Here is a sample that shows the index `4` have a attribute Unicode is `uniE19B` and after we checking the **FontDrop!** website, we could know the meaning of font is `(`


**<p align="center">XML Font format - GlyphOrder and GlyphID tags</p>**
<p align="center">
  <img src="../master/Images/Anti-scraping-font-glyph-ids.png?raw=true" width="640px">
</p>

Now, we could call the `getGlyphOrder` method to get the contents of `GlyphOrder` tags by using `fonttools` package :

```python
# The getGlyphOrder method will return array and the array will show the data orderly according to the index attribue of GlyphID tag in the GlyphOrder parent tag.
orders: List[str] = font.getGlyphOrder()
```

**<p align="center">The data after calling the getGlyphOrder method</p>**
<p align="center">
  <img src="../master/Images/python-font-getGlyphOrder.png?raw=true">
</p>


#### (2.) `TTGlyph` and `contour` tags - Font contours and coordinate 

**TTGlyph** and **contour** tagsï¼š **TTGlyph** could record the contour information which mapping to unicode encoding in the **GlyphID**. The information about  contour include the minimum and maximun width of X coordniate, height of Y coordniate width and contour coordinate in **contour** tag.

Because the fonts in the font file are described and identified by the contour, there won't be any tags telling the word what the word is. It only record the ã€ŒContourã€of the word, but we could understand what the text is by using software like **FontDrop!**, **[FontCreator]** ..so on and we could also find the contour coordinate in these software.

for example, the previous information shows the tag index of `GlyphID` is `4` and the Unicode is `uniE19B` , so we could find the contour information by encoding number `uniE19B`. Here you could see the contour coordinate is the same as the font `(` in the **FontDrop!**.

**<p align="center">XML Font format - TTGlyph and contour tags</p>**
<p align="center">
  <img src="../master/Images/Anit-scraping-glyph-contours.png?raw=true" width="640px">
</p>

In `fonttools` library, we could get all `TTGlyph` tags and find the contour information through call `get` method and set the `glyf` tag value :

**<p align="center">XML Font format - How to get the information of TTGlyph and contour tags</p>**
<p align="center">
  <img src="../master/Images/python-get-glyph-coordinates.png?raw=true">
</p>

#### (3.) `cmap` and `map` tags  - Other unicode mapping

**cmap** and **map** tagsï¼šé€™å…©å€‹æ¨™ç±¤ç´€éŒ„äº†å­—å‹ä¸­æ¯å€‹å­—çš„å…¶ä»– Unicode ç·¨ç¢¼ï¼Œä¾‹å¦‚é€™é‚Šçš„ `uniE0AF`ï¼Œ é¦–å…ˆ `code` å±¬æ€§æœƒçœ‹åˆ°åŒæ¨£æ˜¯åŒæ¨£æ•¸å€¼çš„ `0xe0af` (å…¶ä¸­çš„ `0x` å¯ä»¥å¿½ç•¥)ï¼Œè€Œé€™å€‹ `code` å±¬æ€§è¡¨ç¤ºäº†å…¶ä»–å¯ä»¥åŒ¹é…çš„ Unicode ç·¨ç¢¼ã€‚

**<p align="center">å­—å‹ XML æ ¼å¼ - cmaps èˆ‡ cmap æ¨™ç±¤</p>**
<p align="center">
  <img src="../master/Images/Anit-scraping-cmaps.png?raw=true" width="640px">
</p>

å†ä¾†å°‹æ‰¾åŸå…ˆæƒ³è¦çš„ä¾‹å­ `uniE19B`ï¼Œå¯ä»¥æ¥è‘—çœ‹åˆ°è©²å­—å‹ `(` å…¶ä»–çš„ Unicode ç·¨ç¢¼ï¼Œå¦‚ä¸‹åœ–ä¸­é™¤äº†è‡ªå·±æœ¬èº«çš„ `code` ç‚º `0xe19b` å¤–ï¼Œå…¶ä»–å°æ‡‰åˆ° `uniE19B` ç·¨ç¢¼çš„ `code` åŒ…å«äº† `0xe20b` èˆ‡ `0xe248`ï¼ŒæŠŠé€™å…©å€‹ Unicode ç·¨ç¢¼ `E20B` èˆ‡ `E248` å°ç…§ä¸€ä¸‹ **FontDrop!** ä¸­ä¾¿å¯ä»¥æ‰¾åˆ°æœ‰ä¸€æ¨¡ä¸€æ¨£çš„æ•¸å€¼ã€‚

**<p align="center">å­—å‹ XML æ ¼å¼ - å…¶ä»–çš„ Unicode ç·¨ç¢¼</p>**
<p align="center">
  <img src="../master/Images/Anit-scraping-cmaps-other-unichar.png?raw=true" width="640px">
</p>

åœ¨ `fonttools` ä¸­ï¼Œå¯ä»¥é€éå‘¼å« `getBestCamp` æ–¹æ³•ä¾†å–å¾—æœ€ä½³çš„ `cmap` æ¨™ç±¤èˆ‡è³‡è¨Šï¼Œå› ç‚ºå­—å‹æª”æ¡ˆä¸­æœ‰å°æ‡‰ä¸åŒ platform çš„ç‰ˆæœ¬ - `cmap_format_4` èˆ‡ `cmap_format_6`ã€‚

```python
# å›å‚³çš„æœƒæ˜¯å­—å…¸æ ¼å¼
orders: Dict[str, str] = font.getBestCamp()
```

**<p align="center">getBestCamp æ–¹æ³•å–å¾—æœ€ä½³çš„ cmap è³‡è¨Š</p>**
<p align="center">
  <img src="../master/Images/python-font-getBestCamp.png?raw=true" width="640px">
</p>

å¦‚ä¸Šåœ–åœ¨ `fonttools` ä¸­æœƒæŠŠ `code` è½‰æ›æˆ 10 é€²åˆ¶çš„è³‡æ–™ï¼Œå› æ­¤åŸæœ¬çš„ `uniE19B` çš„ `code` ç‚º `0xe19b` ä¾¿æœƒè½‰æ›æˆ `57755`ï¼Œæ‰€ä»¥åœ¨ä½¿ç”¨æ™‚ï¼Œè¦è¿‘å¾—è™•ç†é€²åˆ¶è½‰æ›ï¼Œçœ‹æ˜¯è¦ä»¥åé€²åˆ¶æ¯”å°ï¼Œé‚„æ˜¯æŠŠ `57755` è½‰æ›æˆ `0xe19b` æ¯”å°ã€‚

åˆ°æ­¤é€™äº›å°±æ˜¯åœ¨å¯¦ä½œè§£æå­—å‹æª”æ™‚ï¼Œå¯ä»¥å”åŠ©åˆ¤æ–·çš„ã€Œæ¨™ç±¤ã€èˆ‡ã€Œå±¬æ€§ã€ï¼Œé›–ç„¶ä¹Ÿå¯ä»¥é€éä¸€äº›è»Ÿé«”ï¼Œå¦‚ **FontCreator** æˆ– **FontDrop!** ä»¥è¦–è¦ºåŒ–çš„æ–¹å¼å¿«é€Ÿåˆ†æå­—å‹æª”ï¼Œä½†æ˜¯ä»å»ºè­°å„²å­˜æˆ XML æª”æ¡ˆä¾†åˆ†æç´°ç¯€ã€‚

æ¥ä¸‹ä¾†å°±ä¾†å›åˆ°ä¸€é–‹å§‹çˆ¬å–ä¸‹ä¾†çš„äº‚ç¢¼è³‡æ–™ï¼Œé€éå…ˆå‰æ‰€ä»‹ç´¹çš„æ–¹å¼ä¾†è§£æèˆ‡ç¿»è­¯å§ï¼

<br/>

### 4. è§£æ HTML æºç¢¼äº‚ç¢¼çš„ç·¨ç¢¼ä¸¦åˆ†æç¿»è­¯

é›–ç„¶åœ¨ HTML æºç¢¼çœ‹åˆ°çš„äº‚ç¢¼ï¼Œä½†é‚£å…¶å¯¦ä»£è¡¨çš„åªæ˜¯å› ç‚ºè©²ã€Œç·¨ç¢¼ã€é­”æœ‰å°æ‡‰çš„æ–‡å­—è€Œå·²ï¼Œæ‰€ä»¥ç•¶æŠ“ä¸‹ä¾†è²¼åˆ° Python ä¸Šæ™‚æœƒçœ‹åˆ°è©² Unicode çš„ç·¨ç¢¼ï¼Œå¦‚ä¸‹åœ–ï¼š

**<p align="center">Python 3 é¡¯ç¤ºè©² HTML æºç¢¼å­—ä¸²ç·¨ç¢¼</p>**
<p align="center">
  <img src="../master/Images/python-show-unicode-encoding-way.png?raw=true">
</p>

ä¸éå› ç‚º Python 3 çš„å­—ä¸²æ˜¯ Unicode æ ¼å¼ï¼Œæ‰€ä»¥åœ¨ Python ä¸­ `print` é¡¯ç¤ºæ™‚æœƒè¢«è‡ªå‹•è½‰æ›ï¼Œä¹Ÿå°±çœ‹ä¸åˆ°åŸä¾†çš„ç·¨ç¢¼æ¨£å­ã€‚ç•¶ç„¶åœ¨åšå­—ä¸²ä¸­çš„å­—å…ƒæ¯”å°ç¿»è­¯æ™‚ä¹Ÿæœƒç…§æˆå½±éŸ¿ï¼Œæ‰€å€‘å¯ä»¥é€é `encode` æŒ‡å®š `unicode-escape` è·³è„«å­—å…ƒå”åŠ©ä¸¦è½‰æ›å› UTF8 ç·¨ç¢¼ï¼Œé€™æ¨£å†å° `\\u` åšå­—ä¸²åˆ‡å‰²ä¸¦ä¾åºåŒ¹é…å³å¯ã€‚

**<p align="center">è—‰ç”± unicode-escape å”åŠ©å­—å…ƒæ¯”å°</p>**
<p align="center">
  <img src="../master/Images/python-unicode-escape.png?raw=true">
</p>

çŸ¥é“äº†å¦‚ä½•åˆ†æèˆ‡æŸ¥çœ‹ HTML äº‚ç¢¼å¾Œï¼Œå†ä¾†å°±è¦é©—è­‰ä¸€é–‹å§‹çš„åœ¨[2.å°‹æ‰¾ CSS ç·¨ç¢¼åçˆ¬èŸ²çš„å­—å‹æª”](./master/Chinese.md#2å°‹æ‰¾-css-ç·¨ç¢¼åçˆ¬èŸ²çš„å­—å‹æª”)ä¸­æåˆ°çš„æ˜¯å¦æ¯æ¬¡è«‹æ±‚çš„ HTML äº‚ç¢¼ç·¨ç¢¼èˆ‡å­—å‹æª”çš†ä¸åŒï¼Œä¸¦ä¸”éå¸¸å¯æƒœçš„æ˜¯æ²’æœ‰éŒ¯...æ¯æ¬¡éƒ½æœƒæ”¹è®Šç·¨ç¢¼ï¼š

**<p align="center">å†æ¬¡è«‹æ±‚å¾Œçš„ HTML ç·¨ç¢¼</p>**
<p align="center">
  <img src="../master/Images/second-request-html.png?raw=true" width="640px">
</p>

**<p align="center">å†æ¬¡è«‹æ±‚å¾Œçš„å­—å‹æª”</p>**
<p align="center">
  <img src="../master/Images/second-request-font.png?raw=true" width="640px">
</p>

é€™ä¹Ÿä½¿ç¿»çˆ¬èŸ²çš„éº»ç…©åº¦å¤šäº†ä¸€äº›ï¼Œä½†æ˜¯å¥½åœ¨ä¸åŒçš„å­—å‹æª”çš„ç´¢å¼•é †åºèˆ‡å­—å‹çš„è¼ªå»“ã„§è‡´ï¼Œæ‰€ä»¥åªè¦é€éä»¥ä¸‹**äº”å€‹æ­¥é©Ÿ**ä¾¿å¯ä»¥è§£æ±ºã€‚

1. æ¯æ¬¡ Request è«‹æ±‚æ™‚ï¼ŒåŒæ™‚å–å¾—å­—å‹æª”æ¡ˆä¸‹è¼‰ã€‚
2. çˆ¬å– HTML å…§å®¹æ¯”é€é `unicode-escape` ç·¨ç¢¼è™•ç†ï¼Œèˆ‡å­—ä¸²åˆ‡å‰²å–å¾—æ¯å€‹ç·¨ç¢¼ã€‚
3. æŠŠç·¨ç¢¼è½‰æ›æˆ 10 é€²åˆ¶ï¼Œé€é `fonttools` å­—å‹å¥—ä»¶çš„ `cmaps` æ‰¾å‡ºä»£è¡¨çš„ç·¨ç¢¼ï¼Œæ¯”å°åŸå…ˆåˆ‡å‰²å¥½çš„ HTML ç·¨ç¢¼åš 10 é€²åˆ¶è½‰æ› `int("è½‰æ›çš„å­—ä¸²", 16)`ã€‚
4. åœ¨é€éä»£è¡¨çš„ç·¨ç¢¼æ‰¾å‡º `GlyphOrder` çš„ç´¢å¼•
5. å»ºç«‹ä¸€å€‹ç´¢å¼•èˆ‡å­—å‹æ–‡å­—çš„å­—å…¸åŒ¹é…ä¸¦è½‰æ›

ç•¶ç„¶é€™é‚„ç®—æ˜¯å®¹æ˜“çš„ï¼Œå¦‚æœæ¯æ¬¡è«‹æ±‚ä¸‹ä¾†çš„å­—å‹æª”æ¡ˆå…§éƒ¨çš„ç´¢å¼•æ–‡å­—é †åºçš†ä¸åŒï¼Œé‚£éº¼å°±è¦é€é `TTFGlyph` çš„ `contour` æ¯”å°å­—å‹è¼ªå»“åº§æ¨™ã€‚

æ›´è¤‡é›œçš„ï¼Œè‹¥æ˜¯é€£æ¯ä¸€æ¬¡çš„è¼ªå»“åº§æ¨™ä¹Ÿä¸åŒï¼Œé‚£éº¼æ­¥é©Ÿäº”çš„å»ºç«‹ç´¢å¼•èˆ‡æ–‡å­—å­—å…¸ï¼Œå°±ä¸èƒ½ä½¿ç”¨äº†ï¼Œè¦æ”¹æˆ OCR åšè¾¨èªäº†..ã€‚

## License
The source code adopt **GNU General Public License v2.0**.

## Reference
1. [çˆ¬èŸ²ä¹‹å­—å‹åçˆ¬ï¼ˆä¸€ï¼‰èµ·é»ç¶²](https://www.itread01.com/content/1544058306.html)
2. [Pythonï¼šçˆ¬èŸ²ä¾‹é … 2ï¼šçˆ¬å–è²“çœ¼é›»å½±â€”â€”ç ´è§£å­—å‹åçˆ¬](https://www.itread01.com/content/1542776590.html)
3. [çˆ¬èŸ²ä¹‹å­—å‹åçˆ¬ï¼ˆä¸‰ï¼‰æ±½è»Šä¹‹å®¶](https://www.itread01.com/content/1547172845.html)
4. [Python çˆ¬èŸ²å…­ï¼šå­—å‹åçˆ¬è™•ç†ï¼ˆè²“çœ¼+æ±½è»Šä¹‹å®¶ï¼‰-2018.10](https://www.itread01.com/content/1544669846.html)
5. [Python3 ä½¿ç”¨ unicode-escape å¤„ç† unicode 16 è¿›åˆ¶å­—ç¬¦ä¸²ç¼–è§£ç é—®é¢˜](https://blog.csdn.net/chuatony/article/details/72628868)
6. [how do I .decode('string-escape') in Python3?](https://stackoverflow.com/questions/14820429/how-do-i-decodestring-escape-in-python3)
7. [How do I convert hex to decimal in Python? [duplicate]](https://stackoverflow.com/questions/9210525/how-do-i-convert-hex-to-decimal-in-python)
